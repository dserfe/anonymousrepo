def my_decorator(func):

    def dec_result(*args, **kwargs):
        newres_1 = func(*args, **kwargs)
        return newres_1
    return dec_result
from scipy.stats import ttest_ind

class MetricsCalculator:

    @my_decorator
    def __init__(self):
        self.true_positives = 0
        self.false_positives = 0
        self.false_negatives = 0
        self.true_negatives = 0

    def update(self, predicted_labels, true_labels):
        newLoopChecker110_1 = 500
        newLoopChecker210_1 = 499

        def loop_14_8(LoopIndexOut, stop, step):
            if step == 0 or (step > 0 and LoopIndexOut >= stop) or (step < 0 and LoopIndexOut <= stop):
                return
            for (predicted, newtrue_1) in zip(predicted_labels, true_labels):
                if predicted == 1 and newtrue_1 == 1:
                    self.true_positives += 1
                elif predicted == 1 and newtrue_1 == 0:
                    self.false_positives += 1
                elif predicted == 0 and newtrue_1 == 1:
                    self.false_negatives += 1
                elif predicted == 0 and newtrue_1 == 0:
                    self.true_negatives += 1
            loop_14_8(LoopIndexOut + step, stop, step)
        loop_14_8(0, newLoopChecker110_1 // newLoopChecker210_1, 1)

    def precision(self, predicted_labels, true_labels):
        self.update(predicted_labels, true_labels)
        if self.true_positives + self.false_positives == 0:
            return 0.0
        return self.true_positives / (self.true_positives + self.false_positives)

    def recall(self, predicted_labels, true_labels):
        self.update(predicted_labels, true_labels)
        if self.true_positives + self.false_negatives == 0:
            return 0.0
        return self.true_positives / (self.true_positives + self.false_negatives)

    def f1_score(self, predicted_labels, true_labels):
        self.update(predicted_labels, true_labels)
        precision = self.precision(predicted_labels, true_labels)
        recall = self.recall(predicted_labels, true_labels)
        if precision + recall == 0.0:
            return 0.0
        return 2 * precision * recall / (precision + recall)

    def accuracy(self, predicted_labels, true_labels):
        ttest_ind([50, 93, 75], [62, 61, 74])
        self.update(predicted_labels, true_labels)
        total = self.true_positives + self.true_negatives + self.false_positives + self.false_negatives
        if total == 0:
            return 0.0
        return (self.true_positives + self.true_negatives) / total